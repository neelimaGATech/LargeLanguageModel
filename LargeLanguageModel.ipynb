{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "debfda24-6dc2-4fb7-b7f2-14da85437bd8",
   "metadata": {},
   "source": [
    "# Large Language Model\n",
    "\n",
    "1. In this notebook I have implemented a large language model from scratch\n",
    "2. The code below follows following steps from a transformder architecture:\n",
    "    - Tokenize the training text input\n",
    "      \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbce0234-4a85-4a89-beef-37529544d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a946ab6-4c8a-4cdc-9ce7-b170f5f742cd",
   "metadata": {},
   "source": [
    "## Preprocessing : Read and Process the Text, Convert to Tokens, Embed into the Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec1520-a2b7-4031-a9c7-41228e4e88cb",
   "metadata": {},
   "source": [
    "## Step 1: Create Tokens from the text read from a book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d031ab9-dcde-400f-8509-ce17ad8f9c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters read from book 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(\"Total characters read from book\" , len(raw_text))\n",
    "# print the first 100 characters \n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7185f29-f064-4aa5-b5a9-19c7ebab5d93",
   "metadata": {},
   "source": [
    "### Tokenize all the text to be used for LLM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7c88f97-5e4c-47e7-91d9-fa0c9517f8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'This', 'is', 'a', 'Test', 'to', 'split', 'words', 'from', 'a', 'large', 'text', '.', '--', 'Just', 'testing']\n"
     ]
    }
   ],
   "source": [
    "# Use Regular Expressions \n",
    "import re\n",
    "\n",
    "text = \"Hello, This is a Test to split words from a large text.-- Just testing\"\n",
    "#result = re.split(r'(\\s)', text)\n",
    "\n",
    "# split by all these characters \n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text) \n",
    "\n",
    "# strip words of whitespaces and also remove whitespaces \n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "39cd55b6-5061-4631-ad34-58ec04d0a0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself', 'in', 'a', 'villa', 'on', 'the', 'Riviera', '.', '(Though', 'I', 'rather', 'thought', 'it', 'would', 'have', 'been', 'Rome', 'or', 'Florence', '.', ')', '\"', 'The', 'height', 'of', 'his', 'glory', '\"', '--', 'that', 'was', 'what', 'the', 'women', 'called', 'it', '.', 'I', 'can', 'hear', 'Mrs', '.', 'Gideon', 'Thwing', '--', 'his', 'last', 'Chicago', 'sitter', '--']\n",
      "Total Tokens: 4685\n"
     ]
    }
   ],
   "source": [
    "# Apply the tokenizer code on entire raw text from the book\n",
    "preprocessed = re.split(r'([,.:;?_!\"\\']|--|\\s)', raw_text)\n",
    "\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(preprocessed[:99])\n",
    "print(\"Total Tokens:\", len(preprocessed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c9ec1-acc0-43c8-9db1-85ec1079a17d",
   "metadata": {},
   "source": [
    "### Convert Tokens to Token IDs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a82e17-df1e-4123-b199-7fc784cc429a",
   "metadata": {},
   "source": [
    "- Build Vocabulary - list of all the unique tokens sorted alphabetically, give them unique indexes\n",
    "- Token id of any token is its inside the vocabulary built so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "487fa6ce-5462-41df-88b5-f50f544e668e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1131\n"
     ]
    }
   ],
   "source": [
    "# Convert preprocessed to a Set so all elements are unique and then sort it\n",
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "403ade9e-8f8d-4813-adb8-06740a16e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate an integer to the words \n",
    "# This is encoding words to number -- we woild need decoder to convert number to corresponding word\n",
    "vocab = {token:integer for integer,token in enumerate(all_words)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "553a8501-313b-4a59-898a-7903ee5c19df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(I', 3)\n",
      "('(Though', 4)\n",
      "(')', 5)\n",
      "(',', 6)\n",
      "('--', 7)\n",
      "('.', 8)\n",
      "(':', 9)\n",
      "(';', 10)\n",
      "('?', 11)\n",
      "('A', 12)\n",
      "('Ah', 13)\n",
      "('Among', 14)\n",
      "('And', 15)\n",
      "('Are', 16)\n",
      "('Arrt', 17)\n",
      "('As', 18)\n",
      "('At', 19)\n",
      "('Be', 20)\n",
      "('Begin', 21)\n",
      "('Burlington', 22)\n",
      "('But', 23)\n",
      "('By', 24)\n",
      "('Carlo', 25)\n",
      "('Chicago', 26)\n",
      "('Claude', 27)\n",
      "('Come', 28)\n",
      "('Croft', 29)\n",
      "('Croft)', 30)\n",
      "('Destroyed', 31)\n",
      "('Devonshire', 32)\n",
      "('Don', 33)\n",
      "('Dubarry', 34)\n",
      "('Emperors', 35)\n",
      "('Florence', 36)\n",
      "('For', 37)\n",
      "('Gallery', 38)\n",
      "('Gideon', 39)\n",
      "('Gisburn', 40)\n",
      "('Gisburns', 41)\n",
      "('Grafton', 42)\n",
      "('Greek', 43)\n",
      "('Grindle', 44)\n",
      "('Grindles', 45)\n",
      "('HAD', 46)\n",
      "('Had', 47)\n",
      "('Hang', 48)\n",
      "('Has', 49)\n",
      "('He', 50)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 50:\n",
    "        break;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d90f9727-b905-4d11-8faa-b657052abcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an Tokenizer class to provide logic for Encoding and Decoding Text using provided Vocabulary\n",
    "# Constructor accepts a vocabulary - which is the dictionary storing the words we want to train on an numerical ids\n",
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        #class variable str_to_int would store vocabulary words with their token ids\n",
    "        self.str_to_int = vocab\n",
    "        #class variables int_to_str will store the mapping of token ids to strings - opposite of vocabulary\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    # Use given vocabulary to store mapping of words to token ids (given in the vocabulary)\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|__|\\s)', text)\n",
    "        preprocessed = [ item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        # use the vocabulary - str to int dictionary to get list of all token ids\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "\n",
    "        # remove spaces before every puctuations\n",
    "        text = re.sub(r'([,.:;?_!\"()\\']|__|\\s)', r'\\1', text)\n",
    "        return text.strip()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8763836-6aba-4a8a-b73c-91b5a54f7cf9",
   "metadata": {},
   "source": [
    "## Instantiate Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0e7e50fe-6adf-47d9-9eb3-d9ab3e621a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 58, 585, 989, 603, 723, 146, 989, 43, 6, 1, 852, 534, 8]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "#test the encoder\n",
    "text = \"\"\"\"It is the last of all the Greek,\" \n",
    "            said he. \"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "54be1899-99fe-462b-8a92-d79409f9faa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It is the last of all the Greek , \" said he .'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the decoder\n",
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9486bc-c817-4063-b216-3cbbb7c5b743",
   "metadata": {},
   "source": [
    "## Special Context Tokens to Handle Unknown Words in Dictionary and End of Text Token\n",
    "\n",
    "### End of Text tokens are embedded between texts from two different sources or unrelated texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "14aa5891-feff-4dd5-9ab9-5f05f05d33d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n"
     ]
    }
   ],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
    "print(len(vocab.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "77833612-7ba8-429a-8deb-61ec4849a544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('younger', 1128),\n",
       " ('your', 1129),\n",
       " ('yourself', 1130),\n",
       " ('<|endoftext|>', 1131),\n",
       " ('<|unk|>', 1132)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab.items())[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dc137cc3-031c-4ed7-adbb-399e88eae3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1128)\n",
      "('your', 1129)\n",
      "('yourself', 1130)\n",
      "('<|endoftext|>', 1131)\n",
      "('<|unk|>', 1132)\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d3716e72-8a66-426c-8f9e-7069bdf8505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        #class variable str_to_int would store vocabulary words with their token ids\n",
    "        self.str_to_int = vocab\n",
    "        #class variables int_to_str will store the mapping of token ids to strings - opposite of vocabulary\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    # Use given vocabulary to store mapping of words to token ids (given in the vocabulary)\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|__|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        #print(self.str_to_int)\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int\n",
    "            else \"<|unk|>\" for item in preprocessed \n",
    "        ]\n",
    "        \n",
    "        # use the vocabulary - str to int dictionary to get list of all token ids\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "\n",
    "        # remove spaces before every puctuations\n",
    "        text = re.sub(r'([,.:;?_!\"()\\']|__|\\s)', r'\\1', text)\n",
    "        return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5389d8cd-c4ff-4c3c-adcf-286e58d93bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In sunlit terraces of palace\n"
     ]
    }
   ],
   "source": [
    "# testing SimpleTokenizerV2\n",
    "tokenizer1 = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In sunlit terraces of palace\"\n",
    "\n",
    "final_text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "227284a1-8350-440f-b6e4-aeb5f6285288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1132, 6, 356, 1127, 629, 976, 11, 1131, 57, 957, 985, 723, 1132]\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizer1.encode(final_text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e535e776-0bc2-4f86-bce1-69b4e88bf7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|> , do you like tea ? <|endoftext|> In sunlit terraces of <|unk|>'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer1.decode(ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495c6d95-d353-4edb-adc2-b8634eb32541",
   "metadata": {},
   "source": [
    "### Some additional tokens used during training of LLMs\n",
    "- [BOS] : Beginning of Sequence\n",
    "- [EOS] : End of Sequence\n",
    "- [PAD] : Padding for smaller batches when they are trained in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f938e-d8c4-43cf-a454-a9b95e46f4f8",
   "metadata": {},
   "source": [
    "## Byte-Pair Encoding : Word can be broken into sub word tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f3138f8-bc74-4025-9904-9bc8f227f2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/neelima/miniconda3/lib/python3.12/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/neelima/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/neelima/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/neelima/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/neelima/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.11.6 tiktoken-0.9.0\n"
     ]
    }
   ],
   "source": [
    "# Use Python open-source tiktoken library that implements BPE (Byte Pair Encoding) Algorithm for Tokenizing\n",
    "# Also used by ChatGPT\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15c78ac4-2236-4ca2-af06-2ccb6806d40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6b788e4-e4e8-47e4-b4c9-8c8bdb55ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate tokenizer using GPT encoder\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c63c367-7713-48cd-883f-198f33e18f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2437, 9892, 348, 620, 3099, 1804, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "# Sample code to use tiktoken tokenizer\n",
    "original_text = (\n",
    "    \"Howdy whachha doing? <|endoftext|> In the sunlit terraces\"\n",
    "    \"of someunknownPlace.\"\n",
    ")\n",
    "# special tokens are assigned tokens towards the end of the dictionary tokens\n",
    "# Their token number usually indicates how big the vocabulary is going to be \n",
    "int_tokens = tokenizer.encode(original_text, allowed_special={'<|endoftext|>'})\n",
    "\n",
    "# vocabulary size is 50255, after which '<|endoftext|>' is assigned the token number 50256\n",
    "# someunknownPlace does not give error as the BPE scheme can successfully break it down in to some byte pair\n",
    "print(int_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57d7b4be-7796-4815-bf4d-edfb81d4590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Howdy whachha doing? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "#Test the Reverse of Tokenizing\n",
    "decoded_text = tokenizer.decode(int_tokens)\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ddca67-ea9e-44cf-980c-76398622517a",
   "metadata": {},
   "source": [
    "## Input - Target Pair Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f12381c-9fc9-4d48-8667-628c38873fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "# Use sliding window approach to create input-target pairs \n",
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a922a614-6358-47af-a29e-6ad227e87668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5095\n"
     ]
    }
   ],
   "source": [
    "# Remove 50 words from the enc_text \n",
    "enc_sample = enc_text[50:]\n",
    "print(len(enc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "057353ea-a6b4-4cfd-b6ef-a29292f7c4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "# Train the LLM, repeatedly by using three different partitions to the enc_text:\n",
    "# input part of length = input context size \n",
    "# target part = one word at index of one position to the right of the input context\n",
    "# hidden part = portion of input text beyond input and target part \n",
    "context_size = 4\n",
    "\n",
    "# input array is an arrat from the text of length = context size\n",
    "x = enc_sample[:context_size]\n",
    "\n",
    "#shift indices by 1 to get the target array , also of length = context size so that \n",
    "y = enc_sample[1: context_size+1]\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90b7bcd8-452d-48c5-a14f-aa333fa865e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] --------> 4920\n",
      "[290, 4920] --------> 2241\n",
      "[290, 4920, 2241] --------> 287\n",
      "[290, 4920, 2241, 287] --------> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(context, \"-------->\" , desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f219f66f-9964-49fb-bcb7-6971d3e1acd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and -------->  established\n",
      " and established -------->  himself\n",
      " and established himself -------->  in\n",
      " and established himself in -------->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    #desired is a single integer so has to be converted to a list\n",
    "    print(tokenizer.decode(context), \"-------->\" , tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e82b7c-b613-49c3-b30e-331598743be4",
   "metadata": {},
   "source": [
    "## Implement a data loader to iterate over input dataset and return batches of data \n",
    "(For next word prediction task)\n",
    "DataLoader class helps load data in batches and utilize parallel processing efficiently\n",
    "\n",
    "- Entire input text will be loaded and stored in form of input tensor: Each row in the tensor would represent one new input context of length 4 from the entire input.\n",
    "  x = tensor([[\"In\", \"the\", \"heart\" , \"of\"],\n",
    "             [\"the\", \"city\" , \"stood\", \"the\"],\n",
    "             [\"old\", \"library\", \".\", \"a\"],\n",
    "  ...\n",
    "  ])\n",
    "- Target tensor: There will be rows of target part of the input text which is an array of predicted word for each combination of inputs. It is one position offset from the entire input\n",
    "  y = tensor([[\"the\", \"heart\", \"of\", \"the\"],\n",
    "  [\"city\", \"stood\", \"the\", \"old\"],\n",
    "  [\"library\", \",\",\"a\",\"relic\"]\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fcbd030-0a11-4f35-b521-f6c3ed328432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need data in form of tensors for future use of PyTorch library \n",
    "# Input Tensors and Target Tensors\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# This class will be used to create dataset in the form of input output pairs for training \n",
    "# context_size = how big each input tensor row should be \n",
    "# how many words should we skip for every iteration\n",
    "# This class implenents the Dataset class of PyTorch\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, input_text, tokenizer, context_size, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        \n",
    "        # Step1: Tokenize the entire input text as we only work with the tokens \n",
    "        token_ids = tokenizer.encode(input_text, allowed_special = {\"<|endoftext|>\"})\n",
    "\n",
    "\n",
    "        # Step2: Read chunks of book text and add them to input and target tensors\n",
    "        for i in range(0, len(token_ids) - context_size , stride):\n",
    "            input_chunk = token_ids[i: i+context_size]\n",
    "            target_chunk = token_ids[i+1:i+context_size+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    # Step3: Return the size of the tensor dataset\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "\n",
    "    # Step4: Return the input row at index 'idx' and corresponding target row at idx. It returns two items x and y\n",
    "    # It is a Map style data loader \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx],self.target_ids[idx]\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80abe194-672c-4db8-b5eb-4a14cbe5cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed above dataset to the Pytorch dataloader to get the capabilities of loading data in batches\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size = 4, max_length=256, stride = 128, \n",
    "                         shuffle=True, drop_last = True, num_workers=0):\n",
    "    #Step1: Initialize tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "\n",
    "    #Step2: Create customer GPT Dataset defined above \n",
    "    #GPTs use a context length of 256 and more \n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "\n",
    "    #Step3: Create dataloader, drop_last = True will let dataloader drop that last batch if it is shorter than the given batch_size\n",
    "    # DAtaloader uses the getitem method defined in the dataset class to return the pairs of input x and target output y values \n",
    "    \n",
    "    data_loader = DataLoader(\n",
    "                dataset,\n",
    "                batch_size = batch_size, \n",
    "                shuffle = shuffle,\n",
    "                drop_last = drop_last,\n",
    "                num_workers = num_workers\n",
    "    )\n",
    "    return data_loader\n",
    "\n",
    "    #Step4: specify number of CPU processes to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "086b2b90-148e-410b-8614-d8d54af7c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "\n",
    "with open(\"the-verdict.txt\", \"r\" ,encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a36dce48-cb9c-4e64-998e-54fb84828b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(\"Pytorch Version\", torch.__version__)\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size = 1, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "\n",
    "# USE PYTHON ITERATOR TO FETCH NEXT AND NEXT BATCHES \n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ff6a7991-1f48-4efd-b7f2-18235a329afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[1807, 3619,  402,  271]]), tensor([[ 3619,   402,   271, 10899]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "70d681ea-1c0f-4419-946b-719291f07ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "#Batch Size = 8\n",
    "\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size = 8 , max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "\n",
    "# USE PYTHON ITERATOR TO FETCH NEXT AND NEXT BATCHES \n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b800b90-c996-4439-8879-ac08ca40535a",
   "metadata": {},
   "source": [
    "## Vector Embeddings / Token Embeddings\n",
    "\n",
    "- Tokens are converted into Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d241e13-6cda-4ff2-b4fe-8565b8e363ab",
   "metadata": {},
   "source": [
    "####  Assume Word Tokenizer \n",
    "- Input text = \"quick fox is in the house\"\n",
    "- Words and their tokens in alphabetical order:\n",
    "  - fox : 0\n",
    "  - house: 1\n",
    "  - in: 2\n",
    "  - is: 3\n",
    "  - quick: 4\n",
    "  - the: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e9424a71-a9bf-4a8f-9e9e-b530cb01d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([ 2,3,4,5])\n",
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "# Using torch library to create an Embedding for given vocab size and output vector dimensions\n",
    "# Embeddings is a dictionary(lookup table) of weights of given vocab size and output dim \n",
    "# Following statement will create an Embedding layer weight matrix of size vocab_size x output_dim (in this case 6 x 3)\n",
    "# The matrix contains weights for NN initialized randomly\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b5201e7-e66b-4044-aa1c-b3e30cd0e515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Print entire tensor for embedding layer \n",
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "35e42bea-718c-49e7-a6a3-e643aa418fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Print the weights at id 3 \n",
    "# Pass argument as tensor 3 \n",
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "92d2c723-8792-4e59-99c8-3dae55e41f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Prints weights for input ids inside input id vector \n",
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838d7ee-b76f-4557-b0a9-0f1c79678d34",
   "metadata": {},
   "source": [
    "## Absolute Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2f27ab7-32f5-4c0f-8443-344d9bd3376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume a vocab size of 50257 and embedded into vector of dimensional 256\n",
    "\n",
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "#First create an embedding layer for the given size of vocab and vector size / output dimension\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "338bc76f-f129-4896-a008-41c44e7d573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Context length\n",
    "max_length = 4 \n",
    "\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=max_length, stride = max_length, shuffle = False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b726d841-625f-471e-9df9-67c082171a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "Input shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"Input shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "254c91cd-b243-44c5-9501-5ad0ca6a09a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "#Use embedding layer to convert each token id in the input tensor to vector of dimension 256\n",
    "# Embedding layer will store and facilitiate fetching vector representation of each input token \n",
    "# If the input token tensor was 8x4: after vector embedding input tensor would be 8x4x256 \n",
    "# this is because each input token would be converted to vector of size 256\n",
    "\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "917b8e44-40e5-4e31-887c-1e16b9180f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add positional embedding information to the embedded vectors\n",
    "# At one time only an input sequence of length 4 tokens (context length) would be given as input to the LLM\n",
    "# Input size for LLM at any point is 4 in order to predict next token or word\n",
    "# Hence only 4 positions are to required to be encoded in any input sequence at a time \n",
    "# Positional Embedding layer size : 4 x vector_dimension = 4 x 256\n",
    "context_length = max_length \n",
    "# create positional embeddings layer\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad580ed5-9600-4d13-94fb-a17a04aaa58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "# Embeddings layers are lookup tables \n",
    "# To get positional embedding vectors we only need to pass the position value 0, 1, 2 or 3\n",
    "# Hence we have pass the array [0, 1, 2, 3]\n",
    "pos_embeggings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeggings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fe720b-3c41-44b5-b63d-5b3186cfd32d",
   "metadata": {},
   "source": [
    "## Final Input Embeddings\n",
    "### Input Embeddings + Positional Embeddings\n",
    "- [8 x 4 x 256] + [4 x 256] = [8 x 4 x 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d630d6b-a6dd-422e-9e41-39a3a86b6589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
